{"cells":[{"cell_type":"markdown","metadata":{"id":"ih0tD5CMIuiP"},"source":["## About IMDB Dataset\n","\n","* データセット: 映画のレビューコメントを集めた大規模なテキストデータ\n","* レビューにはポジティブかネガティブかのラベルがついている\n","    - 実際のラベル対応については以下も参考になる\n","    - https://note.com/e_dao/n/ne73960e21b79\n","* 25,000件の訓練データ、25,000件のテストデータが含まれる"]},{"cell_type":"markdown","metadata":{"id":"QTuaqUr-FgI2"},"source":["## Import Libraries and Set Device"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","import os, sys\n","print('Current Directory: ', os.getcwd())\n","\n","ROOT_PATH = '/content/drive/My Drive/Colab Notebooks/'\n","sys.path.append(ROOT_PATH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hvxfW2QQ5EnA","executionInfo":{"status":"ok","timestamp":1708438936878,"user_tz":-540,"elapsed":29210,"user":{"displayName":"裏谷俊平","userId":"18389618188141333486"}},"outputId":"f65af509-1717-4dbd-9832-9cfb52d9e41a"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n","Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","Current Directory:  /content\n"]}]},{"cell_type":"code","source":["!pip install portalocker==2.3.0\n","!pip install torch==1.13.1\n","!pip install torchdata==0.6.0\n","!pip install torchtext==0.15.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MgX2Usn7GacD","executionInfo":{"status":"ok","timestamp":1708436168283,"user_tz":-540,"elapsed":201763,"user":{"displayName":"裏谷俊平","userId":"18389618188141333486"}},"outputId":"be1c9795-b8b7-4c97-934c-5fce81a57928"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting portalocker==2.3.0\n","  Downloading portalocker-2.3.0-py2.py3-none-any.whl (15 kB)\n","Installing collected packages: portalocker\n","Successfully installed portalocker-2.3.0\n","Collecting torch==1.13.1\n","  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (4.9.0)\n","Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.1)\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.1)\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13.1)\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13.1)\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (67.7.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (0.42.0)\n","Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.1.0+cu121\n","    Uninstalling torch-2.1.0+cu121:\n","      Successfully uninstalled torch-2.1.0+cu121\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 1.13.1 which is incompatible.\n","torchdata 0.7.0 requires torch==2.1.0, but you have torch 1.13.1 which is incompatible.\n","torchtext 0.16.0 requires torch==2.1.0, but you have torch 1.13.1 which is incompatible.\n","torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1\n","Collecting torchdata==0.6.0\n","  Downloading torchdata-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.0) (2.0.7)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.0) (2.31.0)\n","Collecting torch==2.0.0 (from torchdata==0.6.0)\n","  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata==0.6.0) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata==0.6.0) (4.9.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata==0.6.0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata==0.6.0) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata==0.6.0) (3.1.3)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata==0.6.0) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata==0.6.0) (11.7.99)\n","Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0->torchdata==0.6.0)\n","  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata==0.6.0) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata==0.6.0) (11.10.3.66)\n","Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0->torchdata==0.6.0)\n","  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0->torchdata==0.6.0)\n","  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0->torchdata==0.6.0)\n","  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0->torchdata==0.6.0)\n","  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0->torchdata==0.6.0)\n","  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0->torchdata==0.6.0)\n","  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting triton==2.0.0 (from torch==2.0.0->torchdata==0.6.0)\n","  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchdata==0.6.0) (67.7.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchdata==0.6.0) (0.42.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchdata==0.6.0) (3.27.9)\n","Collecting lit (from triton==2.0.0->torch==2.0.0->torchdata==0.6.0)\n","  Downloading lit-17.0.6.tar.gz (153 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.6.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.6.0) (3.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.6.0) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0->torchdata==0.6.0) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0->torchdata==0.6.0) (1.3.0)\n","Building wheels for collected packages: lit\n","  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lit: filename=lit-17.0.6-py3-none-any.whl size=93255 sha256=c4e42894118cdcc7a467f79f45a2c35641470b1b183b6ad2d2a123ad47a210be\n","  Stored in directory: /root/.cache/pip/wheels/30/dd/04/47d42976a6a86dc2ab66d7518621ae96f43452c8841d74758a\n","Successfully built lit\n","Installing collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-cupti-cu11, nvidia-cusolver-cu11, triton, torch, torchdata\n","  Attempting uninstall: triton\n","    Found existing installation: triton 2.1.0\n","    Uninstalling triton-2.1.0:\n","      Successfully uninstalled triton-2.1.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.13.1\n","    Uninstalling torch-1.13.1:\n","      Successfully uninstalled torch-1.13.1\n","  Attempting uninstall: torchdata\n","    Found existing installation: torchdata 0.7.0\n","    Uninstalling torchdata-0.7.0:\n","      Successfully uninstalled torchdata-0.7.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.0.0 which is incompatible.\n","torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.0 which is incompatible.\n","torchtext 0.16.0 requires torchdata==0.7.0, but you have torchdata 0.6.0 which is incompatible.\n","torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed lit-17.0.6 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 torchdata-0.6.0 triton-2.0.0\n","Collecting torchtext==0.15.2\n","  Downloading torchtext-0.15.2-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.2) (4.66.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.2) (2.31.0)\n","Collecting torch==2.0.1 (from torchtext==0.15.2)\n","  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.2) (1.25.2)\n","Collecting torchdata==0.6.1 (from torchtext==0.15.2)\n","  Downloading torchdata-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (4.9.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (3.1.3)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (2.0.0)\n","Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.1->torchtext==0.15.2) (2.0.7)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchtext==0.15.2) (67.7.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchtext==0.15.2) (0.42.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchtext==0.15.2) (3.27.9)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchtext==0.15.2) (17.0.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.2) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.2) (3.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.2) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchtext==0.15.2) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchtext==0.15.2) (1.3.0)\n","Installing collected packages: torch, torchdata, torchtext\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.0.0\n","    Uninstalling torch-2.0.0:\n","      Successfully uninstalled torch-2.0.0\n","  Attempting uninstall: torchdata\n","    Found existing installation: torchdata 0.6.0\n","    Uninstalling torchdata-0.6.0:\n","      Successfully uninstalled torchdata-0.6.0\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.16.0\n","    Uninstalling torchtext-0.16.0:\n","      Successfully uninstalled torchtext-0.16.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n","torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-2.0.1 torchdata-0.6.1 torchtext-0.15.2\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Faynfu7DFgI2","executionInfo":{"status":"ok","timestamp":1708436172169,"user_tz":-540,"elapsed":3898,"user":{"displayName":"裏谷俊平","userId":"18389618188141333486"}},"outputId":"a361c4a1-c7ef-4abe-ef47-e2d00dfad860"},"outputs":[{"output_type":"stream","name":"stdout","text":["The device is :  cuda\n"]}],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader, TensorDataset , RandomSampler, SequentialSampler\n","from torchtext.datasets import IMDB\n","from torchtext.data.functional import to_map_style_dataset\n","from torch.optim import AdamW\n","\n","import transformers\n","from transformers import BertForSequenceClassification, BertTokenizerFast\n","from transformers import AdamW\n","from transformers import AutoModel, BertTokenizerFast\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from sklearn.metrics import accuracy_score\n","import random\n","\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"The device is : \", device)"]},{"cell_type":"markdown","metadata":{"id":"R4ZIf1ggFgI4"},"source":["## Encode & Create Dataset"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BhXNiH6gFgI4","executionInfo":{"status":"ok","timestamp":1708439950653,"user_tz":-540,"elapsed":2146,"user":{"displayName":"裏谷俊平","userId":"18389618188141333486"}},"outputId":"0d7c6a00-7247-4f42-8b44-9faf2a4914c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train DataLoader has 128 batches.\n","Test DataLoader has 16 batches.\n","Train labels unique values: tensor([0, 1])\n","Test labels unique values: tensor([0, 1])\n"]}],"source":["# データセットをロードしてマップスタイルに変換\n","train_iter, test_iter = IMDB()\n","train_dataset = to_map_style_dataset(train_iter)\n","test_dataset = to_map_style_dataset(test_iter)\n","\n","# トークナイザの初期化\n","tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n","\n","# Positiveの場合(2→1)に変換する\n","# Negativeの場合(1→0)に変換する\n","def adjust_labels(labels):\n","    labels = labels - 1\n","    return labels\n","\n","# サンプリング\n","train_num = 1024\n","test_num = 128\n","train_sampled = random.sample(list(train_dataset), train_num)\n","test_sampled = random.sample(list(test_dataset), test_num)\n","\n","# サンプリングされたデータセットからテキストを抽出（エンコード時にreturn tensorが指定できるので今はテンソル化不要）\n","train_texts = [text for (_, text) in train_sampled]\n","test_texts = [text for (_, text) in test_sampled]\n","\n","# サンプリングされたデータセットから整数ラベルを抽出\n","train_labels = torch.tensor([label for (label, _) in train_sampled], dtype=torch.long)\n","test_labels = torch.tensor([label for (label, _) in test_sampled], dtype=torch.long)\n","\n","train_labels = adjust_labels(train_labels)\n","test_labels = adjust_labels(test_labels)\n","\n","\n","# データのエンコード（トークン化）\n","encoded_train = tokenizer(train_texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n","encoded_test = tokenizer(test_texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n","\n","# エンコードされたデータからTensorDatasetを作成\n","train_dataset = TensorDataset(encoded_train['input_ids'], encoded_train['attention_mask'], train_labels)\n","test_dataset = TensorDataset(encoded_test['input_ids'], encoded_test['attention_mask'], test_labels)\n","\n","# DataLoaderの設定\n","batch_size = 8\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False) # Testはシャッフルしない\n","\n","print(f\"Train DataLoader has {len(train_loader)} batches.\")\n","print(f\"Test DataLoader has {len(test_loader)} batches.\")\n","\n","print(\"Train labels unique values:\", torch.unique(train_labels))\n","print(\"Test labels unique values:\", torch.unique(test_labels))"]},{"cell_type":"markdown","metadata":{"id":"jdoy98ppFgI5"},"source":["## Demonstration"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"i7bh-XQ-FgI5","executionInfo":{"status":"ok","timestamp":1708436217123,"user_tz":-540,"elapsed":2991,"user":{"displayName":"裏谷俊平","userId":"18389618188141333486"}},"colab":{"base_uri":"https://localhost:8080/","height":120,"referenced_widgets":["5c8c357205674fe38ed6c1f7a480cfaf","a302fba791844c56a0daeffafeed3707","904216e6fc7248d980173841a9fa3917","d46a098a0f0c41d4b052a940808271f9","95c97044814c4b00b32187d0dc51b0c7","0a742181770b44afb5fa452ec82e24e2","af55c9289dc3477095d47dc316cdd8c6","f10b088822a444d5918a86c3734da7f4","7547d83dc6364791b1264995ea8c25f4","581bf872f6d944b8a730c4cbacded245","dfc06ced94f342d79d6ea0cacf92709f"]},"outputId":"2401c277-5ee2-4505-b783-de53eb4cf10f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c8c357205674fe38ed6c1f7a480cfaf"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'input_ids': tensor([[  101,  1045,  2066,  8645,  4063,  2386,   102],\n","        [  101,  1045, 18959,  2023,  3185,   102,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1, 1, 0]])}\n"]}],"source":["# インスタンス化\n","bert = AutoModel.from_pretrained(\"bert-base-uncased\")\n","tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n","\n","# デモ用のテキスト\n","texts = [\"I like spyderman\", \"I dislike this movie\"]\n","\n","# テキストのバッチをエンコード\n","input_ids = tokenizer.batch_encode_plus(\n","    texts,  # テキストのリストを直接渡す\n","    padding=True,  # 全てのシーケンスが同じ長さになるようにパディング\n","    return_token_type_ids=True,  # トークンタイプIDを返す\n","    truncation=True,  # 最大長を超えるトークンを切り捨てる\n","    return_tensors=\"pt\"  # PyTorchのテンソルとして結果を返す\n",")\n","\n","print(input_ids)"]},{"cell_type":"markdown","metadata":{"id":"ghW0idMYFgI5"},"source":["## Modeling"]},{"cell_type":"code","source":["#GPUのキャッシュクリア\n","import gc\n","gc.collect()  # ガベージコレクションの強制実行\n","torch.cuda.empty_cache()  # CUDAキャッシュのクリア"],"metadata":{"id":"9umyikCU0cs3","executionInfo":{"status":"ok","timestamp":1708437673481,"user_tz":-540,"elapsed":1040,"user":{"displayName":"裏谷俊平","userId":"18389618188141333486"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","execution_count":17,"metadata":{"id":"OvNR8qflmihI","executionInfo":{"status":"ok","timestamp":1708438648208,"user_tz":-540,"elapsed":971240,"user":{"displayName":"裏谷俊平","userId":"18389618188141333486"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d034c071-9251-40d3-cba7-21644017ef89"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch:  0 / 10\n","Loss:  73.35677639394999\n","Epoch:  1 / 10\n","Loss:  41.124380711466074\n","Epoch:  2 / 10\n","Loss:  26.27963793091476\n","Epoch:  3 / 10\n","Loss:  16.638293244875968\n","Epoch:  4 / 10\n","Loss:  13.831583279184997\n","Epoch:  5 / 10\n","Loss:  7.243148343171924\n","Epoch:  6 / 10\n","Loss:  1.819473164039664\n","Epoch:  7 / 10\n","Loss:  6.886432120751124\n","Epoch:  8 / 10\n","Loss:  1.6592801148653962\n","Epoch:  9 / 10\n","Loss:  3.7272749455296434\n"]}],"source":["# モデルの初期化（感情分析タスクのための2つのラベル）\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n","model.to(device)\n","\n","# ハイパーパラメータの設定 （損失関数はモデル内に含まれてるので不要）\n","# インスタンス化することでclassifier.biasとclassifier.weightを初期化\n","# AdamWはtransformersでなくpytorchのものを使用\n","from torch.optim import AdamW\n","optimizer = AdamW(model.parameters(), lr=5e-5)\n","epochs = 10\n","\n","\n","\n","# トレーニングモードに設定\n","model.train()\n","\n","for epoch in range(epochs):\n","\n","    print(\"Epoch: \", epoch, \"/\", epochs)\n","    model.train()\n","    total_loss = 0\n","\n","    for batch in train_loader:\n","        input_ids = batch[0].to(model.device) # train_loaderには[input_ids, attention_mask, labels]が入ってる\n","        attention_mask = batch[1].to(model.device)\n","        labels = batch[2].to(model.device)\n","\n","        #オプティマイザの初期化\n","        optimizer.zero_grad()\n","\n","        # 順伝播計算\n","        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","        total_loss += loss.item()\n","\n","        #逆伝播計算\n","        loss.backward()\n","\n","        #重みの更新\n","        optimizer.step()\n","\n","    print('Loss: ', total_loss)"]},{"cell_type":"code","source":["#パラメータの保存\n","MODEL_SAVE_PATH = \"model_weights_bert.pth\"  # 保存先のファイルパス\n","torch.save(model.state_dict(), MODEL_SAVE_PATH)\n","\n","'''\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)  # 新しいモデルインスタンスの作成\n","model.load_state_dict(torch.load(model_save_path))  # 保存したパラメータの読み込み\n","model.eval()  # 評価モードに設定\n","'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":71},"id":"ywLiC2gC4RWl","executionInfo":{"status":"ok","timestamp":1708439118914,"user_tz":-540,"elapsed":1258,"user":{"displayName":"裏谷俊平","userId":"18389618188141333486"}},"outputId":"8f4154a9-a2dc-4029-841c-a9699903fc70"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)  # 新しいモデルインスタンスの作成\\nmodel.load_state_dict(torch.load(model_save_path))  # 保存したパラメータの読み込み\\nmodel.eval()  # 評価モードに設定\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"YLi3NPZ0FgI6"},"source":["## Validation"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"UROcQ4ppFgI6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708439153750,"user_tz":-540,"elapsed":4133,"user":{"displayName":"裏谷俊平","userId":"18389618188141333486"}},"outputId":"9c239d4c-7991-4ca5-fafa-26f6294e0774"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 87.50%\n"]}],"source":["def Evaluate(model, dataloader):\n","    model.eval() # モデルを評価モードに設定\n","    predictions = []\n","    true_labels = []\n","\n","    for batch in dataloader:\n","        input_ids = batch[0].to(model.device)\n","        attention_mask = batch[1].to(model.device)\n","        labels = batch[2].to(model.device)\n","\n","        with torch.no_grad(): # 勾配計算を無効化\n","            outputs = model(input_ids, attention_mask=attention_mask) # labelは予測には不要\n","\n","\n","        logits = outputs.logits # logits: 各クラスに対する生の予測値\n","        logits = logits.detach().cpu().numpy() #logitsテンソルを計算グラフから分離し, 勾配計算から除外\n","        label_ids = labels.to('cpu').numpy() #CPUに移動させることでnumpyが使える\n","\n","        # 予測値と対応する正解ラベルを保存\n","        predictions.append(logits)\n","        true_labels.append(label_ids)\n","\n","    # 予測値を評価\n","    predictions = np.concatenate(predictions, axis=0) #predictionsリストに保存された全てのバッチの予測値を1つのNumPy配列に結合\n","    true_labels = np.concatenate(true_labels, axis=0)#true_labelsリストに保存された全てのバッチの真のラベルを1つのNumPy配列に結合\n","    preds_flat = np.argmax(predictions, axis=1).flatten()  # 予測値（ロジット）から、最も高い値を持つクラスのインデックス（予測されたラベル）を選択し、配列を1次元に平坦化（flatten）することで各入力に対する最終的なクラス予測が得る\n","    labels_flat = true_labels.flatten() # 真のラベルの配列を1次元に平坦化することで、予測値と同じ形式で真のラベルを扱うことができ、比較が容易になる\n","\n","\n","\n","    # 正解率を計算\n","    accuracy = accuracy_score(labels_flat, preds_flat)\n","    return accuracy\n","\n","# テストデータセット上でモデルを評価\n","accuracy = Evaluate(model, test_loader)\n","print(f\"Accuracy: {accuracy * 100:.2f}%\")"]},{"cell_type":"markdown","source":["## Use Model for Another Task"],"metadata":{"id":"uBEkNyLH-jEr"}},{"cell_type":"code","source":["from transformers import BertTokenizer\n","\n","# トークナイザの初期化\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","# オリジナルのテキスト\n","text = \"This is a great movie!\"\n","\n","# テキストをモデルの入力形式に変換\n","inputs = tokenizer(\n","    text,\n","    return_tensors=\"pt\",\n","    padding=True,\n","    truncation=True,\n","    max_length=512\n","    )\n","\n","# 評価モードに設定\n","model.eval()\n","\n","# GPUに移動\n","inputs = {key: value.to(device) for key, value in inputs.items()}\n","\n","# 推論\n","with torch.no_grad():\n","    outputs = model(**inputs)\n","    predictions = outputs.logits.argmax(dim=-1).item()\n","\n","# 結果\n","if predictions == 1:\n","    print(\"Positive review detected!\")\n","else:\n","    print(\"Negative review detected!\")"],"metadata":{"id":"Yv105qmT7Zmn","executionInfo":{"status":"ok","timestamp":1708440100588,"user_tz":-540,"elapsed":591,"user":{"displayName":"裏谷俊平","userId":"18389618188141333486"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HaSJjy82IP1q"},"source":["## Optional : Original Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BpneADdUoQLU"},"outputs":[],"source":["'''\n","import torch.nn as nn\n","\n","class BERTBinaryClassification(nn.Module):\n","    def __init__(self, bert):\n","        super().__init__()\n","        self.bert = bert\n","        self.dropout = nn.Dropout(0.2)\n","        self.relu = nn.ReLU()\n","        self.fc1 = nn.Linear(768, 256)\n","        self.fc2 = nn.Linear(256, 2)\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.bert(input_ids, attention_mask=attention_mask)\n","        x = self.fc1(outputs.pooler_output) #\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        x = self.fc2(x)\n","        return x\n","\n","\n","model = BERTBinaryClassification(bert)\n","model = model.to(device)\n","\n","#省略\n","'''"]},{"cell_type":"markdown","source":["## Fin"],"metadata":{"id":"goayuxAW9-f5"}}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"widgets":{"application/vnd.jupyter.widget-state+json":{"5c8c357205674fe38ed6c1f7a480cfaf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a302fba791844c56a0daeffafeed3707","IPY_MODEL_904216e6fc7248d980173841a9fa3917","IPY_MODEL_d46a098a0f0c41d4b052a940808271f9"],"layout":"IPY_MODEL_95c97044814c4b00b32187d0dc51b0c7"}},"a302fba791844c56a0daeffafeed3707":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a742181770b44afb5fa452ec82e24e2","placeholder":"​","style":"IPY_MODEL_af55c9289dc3477095d47dc316cdd8c6","value":"model.safetensors: 100%"}},"904216e6fc7248d980173841a9fa3917":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f10b088822a444d5918a86c3734da7f4","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7547d83dc6364791b1264995ea8c25f4","value":440449768}},"d46a098a0f0c41d4b052a940808271f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_581bf872f6d944b8a730c4cbacded245","placeholder":"​","style":"IPY_MODEL_dfc06ced94f342d79d6ea0cacf92709f","value":" 440M/440M [00:01&lt;00:00, 384MB/s]"}},"95c97044814c4b00b32187d0dc51b0c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a742181770b44afb5fa452ec82e24e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af55c9289dc3477095d47dc316cdd8c6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f10b088822a444d5918a86c3734da7f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7547d83dc6364791b1264995ea8c25f4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"581bf872f6d944b8a730c4cbacded245":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfc06ced94f342d79d6ea0cacf92709f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}